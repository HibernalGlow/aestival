"""
dissolvef é€‚é…å™¨
æ–‡ä»¶å¤¹è§£æ•£å·¥å…· - è§£æ•£åµŒå¥—/å•åª’ä½“/å•åŽ‹ç¼©åŒ…/ç›´æŽ¥è§£æ•£æ–‡ä»¶å¤¹

åŠŸèƒ½ï¼š
- nested: è§£æ•£åµŒå¥—çš„å•ä¸€æ–‡ä»¶å¤¹ï¼ˆæ”¯æŒç›¸ä¼¼åº¦é™åˆ¶ï¼‰
- media: è§£æ•£å•åª’ä½“æ–‡ä»¶å¤¹
- archive: è§£æ•£å•åŽ‹ç¼©åŒ…æ–‡ä»¶å¤¹ï¼ˆæ”¯æŒç›¸ä¼¼åº¦é™åˆ¶ï¼‰
- direct: ç›´æŽ¥è§£æ•£æŒ‡å®šæ–‡ä»¶å¤¹
- undo: æ’¤é”€æ“ä½œ
"""

import json
import os
import shutil
from datetime import datetime
from difflib import SequenceMatcher
from pathlib import Path
from typing import Callable, Dict, List, Optional, Tuple

from pydantic import BaseModel, Field

from .base import BaseAdapter, AdapterOutput


def calculate_similarity(str1: str, str2: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ (0.0 - 1.0)"""
    if not str1 or not str2:
        return 0.0
    # ç§»é™¤æ‰©å±•åè¿›è¡Œæ¯”è¾ƒ
    name1 = Path(str1).stem if '.' in str1 else str1
    name2 = Path(str2).stem if '.' in str2 else str2
    return SequenceMatcher(None, name1.lower(), name2.lower()).ratio()


class DissolveOperation(BaseModel):
    """å•ä¸ªè§£æ•£æ“ä½œè®°å½•"""
    type: str  # 'move' | 'delete_dir'
    src: str
    dst: Optional[str] = None
    timestamp: str


class DissolveUndoRecord(BaseModel):
    """æ’¤é”€è®°å½•"""
    id: str
    timestamp: str
    mode: str  # 'nested' | 'archive' | 'media' | 'direct'
    path: str
    operations: List[DissolveOperation]
    count: int


class DissolvefInput(BaseModel):
    """dissolvef è¾“å…¥å‚æ•°"""
    action: str = Field(default="dissolve", description="æ“ä½œç±»åž‹: dissolve, undo, list_undo")
    path: str = Field(default="", description="è¦å¤„ç†çš„æ–‡ä»¶å¤¹è·¯å¾„")
    nested: bool = Field(default=True, description="è§£æ•£åµŒå¥—çš„å•ä¸€æ–‡ä»¶å¤¹")
    media: bool = Field(default=True, description="è§£æ•£å•åª’ä½“æ–‡ä»¶å¤¹")
    archive: bool = Field(default=True, description="è§£æ•£å•åŽ‹ç¼©åŒ…æ–‡ä»¶å¤¹")
    direct: bool = Field(default=False, description="ç›´æŽ¥è§£æ•£æŒ‡å®šæ–‡ä»¶å¤¹")
    preview: bool = Field(default=False, description="é¢„è§ˆæ¨¡å¼ï¼Œä¸å®žé™…æ‰§è¡Œ")
    exclude: Optional[str] = Field(default=None, description="æŽ’é™¤å…³é”®è¯ï¼Œé€—å·åˆ†éš”")
    file_conflict: str = Field(default="auto", description="æ–‡ä»¶å†²çªå¤„ç†: auto/skip/overwrite/rename")
    dir_conflict: str = Field(default="auto", description="ç›®å½•å†²çªå¤„ç†: auto/skip/overwrite/rename")
    # ç›¸ä¼¼åº¦é™åˆ¶
    similarity_threshold: float = Field(default=0.6, description="ç›¸ä¼¼åº¦é˜ˆå€¼ (0.0-1.0)ï¼Œåªæœ‰è¶…è¿‡æ­¤å€¼æ‰è§£æ•£")
    enable_similarity: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨ç›¸ä¼¼åº¦æ£€æµ‹")
    # æ’¤é”€å‚æ•°
    undo_id: str = Field(default="", description="è¦æ’¤é”€çš„æ“ä½œ ID")


class DissolvefOutput(AdapterOutput):
    """dissolvef è¾“å‡ºç»“æžœ"""
    nested_count: int = Field(default=0, description="è§£æ•£çš„åµŒå¥—æ–‡ä»¶å¤¹æ•°é‡")
    media_count: int = Field(default=0, description="è§£æ•£çš„å•åª’ä½“æ–‡ä»¶å¤¹æ•°é‡")
    archive_count: int = Field(default=0, description="è§£æ•£çš„å•åŽ‹ç¼©åŒ…æ–‡ä»¶å¤¹æ•°é‡")
    direct_files: int = Field(default=0, description="ç›´æŽ¥è§£æ•£ç§»åŠ¨çš„æ–‡ä»¶æ•°")
    direct_dirs: int = Field(default=0, description="ç›´æŽ¥è§£æ•£ç§»åŠ¨çš„ç›®å½•æ•°")
    skipped_count: int = Field(default=0, description="å› ç›¸ä¼¼åº¦ä¸è¶³è·³è¿‡çš„æ•°é‡")
    operation_id: str = Field(default="", description="æ“ä½œ IDï¼ˆç”¨äºŽæ’¤é”€ï¼‰")
    undo_records: List[Dict] = Field(default_factory=list, description="æ’¤é”€è®°å½•åˆ—è¡¨")


class DissolvefAdapter(BaseAdapter):
    """
    dissolvef é€‚é…å™¨
    
    åŠŸèƒ½ï¼šæ–‡ä»¶å¤¹è§£æ•£å·¥å…·ï¼Œæ”¯æŒç›¸ä¼¼åº¦é™åˆ¶å’Œæ’¤é”€
    """
    
    name = "dissolvef"
    display_name = "æ–‡ä»¶å¤¹è§£æ•£"
    description = "è§£æ•£åµŒå¥—æ–‡ä»¶å¤¹ã€å•åª’ä½“æ–‡ä»¶å¤¹ã€å•åŽ‹ç¼©åŒ…æ–‡ä»¶å¤¹æˆ–ç›´æŽ¥è§£æ•£ï¼Œæ”¯æŒç›¸ä¼¼åº¦é™åˆ¶å’Œæ’¤é”€"
    category = "file"
    icon = "ðŸ“‚"
    required_packages = ["dissolvef"]
    input_schema = DissolvefInput
    output_schema = DissolvefOutput
    
    # æ’¤é”€è®°å½•å­˜å‚¨è·¯å¾„
    _undo_dir: Path = Path.home() / ".dissolvef" / "undo"
    
    def __init__(self):
        super().__init__()
        self._undo_dir.mkdir(parents=True, exist_ok=True)
    
    def _import_module(self) -> Dict:
        """æ‡’åŠ è½½å¯¼å…¥ dissolvef æ¨¡å—"""
        from dissolvef import (
            flatten_single_subfolder,
            release_single_media_folder,
            dissolve_folder
        )
        from dissolvef.archive import release_single_archive_folder
        return {
            "flatten_single_subfolder": flatten_single_subfolder,
            "release_single_media_folder": release_single_media_folder,
            "dissolve_folder": dissolve_folder,
            "release_single_archive_folder": release_single_archive_folder
        }
    
    async def execute(
        self,
        input_data: DissolvefInput,
        on_progress: Optional[Callable[[int, str], None]] = None,
        on_log: Optional[Callable[[str], None]] = None
    ) -> DissolvefOutput:
        """æ‰§è¡Œæ–‡ä»¶å¤¹è§£æ•£"""
        action = input_data.action.lower()
        
        if action == "undo":
            return await self._undo(input_data, on_progress, on_log)
        elif action == "list_undo":
            return await self._list_undo(on_log)
        else:
            return await self._dissolve(input_data, on_progress, on_log)
    
    def _save_undo_record(self, record: DissolveUndoRecord):
        """ä¿å­˜æ’¤é”€è®°å½•"""
        file_path = self._undo_dir / f"{record.id}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(record.model_dump_json(indent=2))
    
    def _load_undo_records(self) -> List[DissolveUndoRecord]:
        """åŠ è½½æ‰€æœ‰æ’¤é”€è®°å½•"""
        records = []
        for file_path in self._undo_dir.glob("*.json"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    records.append(DissolveUndoRecord(**data))
            except Exception:
                pass
        # æŒ‰æ—¶é—´å€’åºæŽ’åˆ—
        records.sort(key=lambda r: r.timestamp, reverse=True)
        return records[:20]  # åªä¿ç•™æœ€è¿‘20æ¡
    
    def _delete_undo_record(self, undo_id: str):
        """åˆ é™¤æ’¤é”€è®°å½•"""
        file_path = self._undo_dir / f"{undo_id}.json"
        if file_path.exists():
            file_path.unlink()
    
    async def _list_undo(self, on_log: Optional[Callable[[str], None]] = None) -> DissolvefOutput:
        """åˆ—å‡ºæ’¤é”€è®°å½•"""
        records = self._load_undo_records()
        if on_log:
            on_log(f"ðŸ“‹ æ‰¾åˆ° {len(records)} æ¡æ’¤é”€è®°å½•")
        
        return DissolvefOutput(
            success=True,
            message=f"æ‰¾åˆ° {len(records)} æ¡æ’¤é”€è®°å½•",
            undo_records=[{
                'id': r.id,
                'timestamp': r.timestamp,
                'mode': r.mode,
                'path': r.path,
                'count': r.count
            } for r in records]
        )
    
    async def _undo(
        self,
        input_data: DissolvefInput,
        on_progress: Optional[Callable[[int, str], None]] = None,
        on_log: Optional[Callable[[str], None]] = None
    ) -> DissolvefOutput:
        """æ’¤é”€æ“ä½œ"""
        undo_id = input_data.undo_id
        if not undo_id:
            # èŽ·å–æœ€æ–°çš„æ’¤é”€è®°å½•
            records = self._load_undo_records()
            if not records:
                return DissolvefOutput(success=False, message="æ²¡æœ‰å¯æ’¤é”€çš„æ“ä½œ")
            undo_id = records[0].id
        
        file_path = self._undo_dir / f"{undo_id}.json"
        if not file_path.exists():
            return DissolvefOutput(success=False, message=f"æ’¤é”€è®°å½•ä¸å­˜åœ¨: {undo_id}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                record = DissolveUndoRecord(**json.load(f))
        except Exception as e:
            return DissolvefOutput(success=False, message=f"è¯»å–æ’¤é”€è®°å½•å¤±è´¥: {e}")
        
        if on_log:
            on_log(f"ðŸ”„ å¼€å§‹æ’¤é”€æ“ä½œ: {record.mode} ({record.count} é¡¹)")
        
        success_count = 0
        failed_count = 0
        
        # é€†åºæ‰§è¡Œæ’¤é”€æ“ä½œ
        for i, op in enumerate(reversed(record.operations)):
            if on_progress:
                progress = int((i + 1) / len(record.operations) * 100)
                on_progress(progress, f"æ’¤é”€ {i + 1}/{len(record.operations)}")
            
            try:
                if op.type == 'move' and op.dst:
                    # ç§»åŠ¨å›žåŽŸä½ç½®
                    dst_path = Path(op.dst)
                    src_path = Path(op.src)
                    if dst_path.exists():
                        # ç¡®ä¿æºç›®å½•å­˜åœ¨
                        src_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.move(str(dst_path), str(src_path))
                        success_count += 1
                        if on_log:
                            on_log(f"  â†©ï¸ {dst_path.name} -> {src_path.parent.name}/")
                    else:
                        failed_count += 1
                        if on_log:
                            on_log(f"  âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {dst_path}")
                elif op.type == 'delete_dir':
                    # é‡æ–°åˆ›å»ºç›®å½•
                    dir_path = Path(op.src)
                    dir_path.mkdir(parents=True, exist_ok=True)
                    success_count += 1
            except Exception as e:
                failed_count += 1
                if on_log:
                    on_log(f"  âŒ æ’¤é”€å¤±è´¥: {e}")
        
        # åˆ é™¤æ’¤é”€è®°å½•
        self._delete_undo_record(undo_id)
        
        if on_log:
            on_log(f"âœ… æ’¤é”€å®Œæˆ: {success_count} æˆåŠŸ, {failed_count} å¤±è´¥")
        
        return DissolvefOutput(
            success=True,
            message=f"æ’¤é”€å®Œæˆ: {success_count} æˆåŠŸ, {failed_count} å¤±è´¥",
            data={'success_count': success_count, 'failed_count': failed_count}
        )
    
    async def _dissolve(
        self,
        input_data: DissolvefInput,
        on_progress: Optional[Callable[[int, str], None]] = None,
        on_log: Optional[Callable[[str], None]] = None
    ) -> DissolvefOutput:
        """æ‰§è¡Œè§£æ•£æ“ä½œ"""
        path = Path(input_data.path)
        
        if not path.exists():
            return DissolvefOutput(success=False, message=f"è·¯å¾„ä¸å­˜åœ¨: {path}")
        
        if not path.is_dir():
            return DissolvefOutput(success=False, message=f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹: {path}")
        
        # å¤„ç†æŽ’é™¤å…³é”®è¯
        exclude_keywords = []
        if input_data.exclude:
            exclude_keywords = [kw.strip() for kw in input_data.exclude.split(',') if kw.strip()]
        
        nested_count = 0
        media_count = 0
        archive_count = 0
        direct_files = 0
        direct_dirs = 0
        skipped_count = 0
        
        mode_prefix = "é¢„è§ˆ" if input_data.preview else ""
        operations: List[DissolveOperation] = []
        
        if on_log:
            on_log(f"ðŸ“‚ {mode_prefix}å¼€å§‹å¤„ç†: {path}")
            if input_data.enable_similarity:
                on_log(f"ðŸ“Š ç›¸ä¼¼åº¦é˜ˆå€¼: {input_data.similarity_threshold:.0%}")
        
        try:
            if input_data.direct:
                # ç›´æŽ¥è§£æ•£æ¨¡å¼ï¼ˆä½¿ç”¨åŽŸæœ‰é€»è¾‘ï¼‰
                try:
                    mod = self.get_module()
                    if on_progress:
                        on_progress(10, "ç›´æŽ¥è§£æ•£æ–‡ä»¶å¤¹...")
                    if on_log:
                        on_log(f"ðŸ”„ {mode_prefix}ç›´æŽ¥è§£æ•£æ–‡ä»¶å¤¹...")
                    
                    success, files_count, dirs_count = mod["dissolve_folder"](
                        path,
                        file_conflict=input_data.file_conflict,
                        dir_conflict=input_data.dir_conflict,
                        preview=input_data.preview,
                        use_status=False
                    )
                    
                    direct_files = files_count
                    direct_dirs = dirs_count
                    
                    if on_log:
                        on_log(f"âœ… {mode_prefix}ç§»åŠ¨ {files_count} ä¸ªæ–‡ä»¶, {dirs_count} ä¸ªç›®å½•")
                except ImportError as e:
                    return DissolvefOutput(success=False, message=f"å¯¼å…¥ dissolvef å¤±è´¥: {e}")
                
            else:
                # å…¶ä»–è§£æ•£æ¨¡å¼ï¼ˆå¸¦ç›¸ä¼¼åº¦æ£€æµ‹ï¼‰
                total_steps = sum([input_data.nested, input_data.media, input_data.archive])
                current_step = 0
                
                if input_data.media:
                    current_step += 1
                    progress_pct = int((current_step / total_steps) * 80) + 10
                    if on_progress:
                        on_progress(progress_pct, "è§£æ•£å•åª’ä½“æ–‡ä»¶å¤¹...")
                    if on_log:
                        on_log(f"ðŸŽ¬ {mode_prefix}è§£æ•£å•åª’ä½“æ–‡ä»¶å¤¹...")
                    
                    try:
                        mod = self.get_module()
                        media_count = mod["release_single_media_folder"](
                            path, exclude_keywords, input_data.preview
                        )
                    except ImportError:
                        pass
                    
                    if on_log:
                        on_log(f"âœ… {mode_prefix}å¤„ç† {media_count} ä¸ªå•åª’ä½“æ–‡ä»¶å¤¹")
                
                if input_data.nested:
                    current_step += 1
                    progress_pct = int((current_step / total_steps) * 80) + 10
                    if on_progress:
                        on_progress(progress_pct, "è§£æ•£åµŒå¥—æ–‡ä»¶å¤¹...")
                    if on_log:
                        on_log(f"ðŸ“ {mode_prefix}è§£æ•£åµŒå¥—æ–‡ä»¶å¤¹...")
                    
                    # ä½¿ç”¨å¸¦ç›¸ä¼¼åº¦æ£€æµ‹çš„åµŒå¥—è§£æ•£
                    count, skipped, ops = await self._dissolve_nested_with_similarity(
                        path, exclude_keywords, input_data.preview,
                        input_data.similarity_threshold if input_data.enable_similarity else 0.0,
                        on_log
                    )
                    nested_count = count
                    skipped_count += skipped
                    operations.extend(ops)
                    
                    if on_log:
                        msg = f"âœ… {mode_prefix}å¤„ç† {nested_count} ä¸ªåµŒå¥—æ–‡ä»¶å¤¹"
                        if skipped > 0:
                            msg += f"ï¼Œè·³è¿‡ {skipped} ä¸ªï¼ˆç›¸ä¼¼åº¦ä¸è¶³ï¼‰"
                        on_log(msg)
                
                if input_data.archive:
                    current_step += 1
                    progress_pct = int((current_step / total_steps) * 80) + 10
                    if on_progress:
                        on_progress(progress_pct, "è§£æ•£å•åŽ‹ç¼©åŒ…æ–‡ä»¶å¤¹...")
                    if on_log:
                        on_log(f"ðŸ“¦ {mode_prefix}è§£æ•£å•åŽ‹ç¼©åŒ…æ–‡ä»¶å¤¹...")
                    
                    # ä½¿ç”¨å¸¦ç›¸ä¼¼åº¦æ£€æµ‹çš„åŽ‹ç¼©åŒ…è§£æ•£
                    count, skipped, ops = await self._dissolve_archive_with_similarity(
                        path, exclude_keywords, input_data.preview,
                        input_data.similarity_threshold if input_data.enable_similarity else 0.0,
                        on_log
                    )
                    archive_count = count
                    skipped_count += skipped
                    operations.extend(ops)
                    
                    if on_log:
                        msg = f"âœ… {mode_prefix}å¤„ç† {archive_count} ä¸ªå•åŽ‹ç¼©åŒ…æ–‡ä»¶å¤¹"
                        if skipped > 0:
                            msg += f"ï¼Œè·³è¿‡ {skipped} ä¸ªï¼ˆç›¸ä¼¼åº¦ä¸è¶³ï¼‰"
                        on_log(msg)
            
            if on_progress:
                on_progress(100, "å¤„ç†å®Œæˆ")
            
            # ä¿å­˜æ’¤é”€è®°å½•ï¼ˆéžé¢„è§ˆæ¨¡å¼ä¸”æœ‰æ“ä½œï¼‰
            operation_id = ""
            if not input_data.preview and operations:
                operation_id = f"dissolve-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
                mode = "nested" if input_data.nested else ("archive" if input_data.archive else "media")
                record = DissolveUndoRecord(
                    id=operation_id,
                    timestamp=datetime.now().isoformat(),
                    mode=mode,
                    path=str(path),
                    operations=operations,
                    count=len(operations)
                )
                self._save_undo_record(record)
                if on_log:
                    on_log(f"ðŸ”„ æ’¤é”€ ID: {operation_id}")
            
            # æž„å»ºç»“æžœæ¶ˆæ¯
            if input_data.direct:
                message = f"{mode_prefix}ç›´æŽ¥è§£æ•£å®Œæˆ: ç§»åŠ¨ {direct_files} ä¸ªæ–‡ä»¶, {direct_dirs} ä¸ªç›®å½•"
            else:
                parts = []
                if input_data.nested:
                    parts.append(f"åµŒå¥— {nested_count}")
                if input_data.media:
                    parts.append(f"åª’ä½“ {media_count}")
                if input_data.archive:
                    parts.append(f"åŽ‹ç¼©åŒ… {archive_count}")
                message = f"{mode_prefix}è§£æ•£å®Œæˆ: {', '.join(parts)}"
                if skipped_count > 0:
                    message += f"ï¼Œè·³è¿‡ {skipped_count}"
            
            if on_log:
                on_log(f"ðŸ“Š {message}")
            
            return DissolvefOutput(
                success=True,
                message=message,
                nested_count=nested_count,
                media_count=media_count,
                archive_count=archive_count,
                direct_files=direct_files,
                direct_dirs=direct_dirs,
                skipped_count=skipped_count,
                operation_id=operation_id,
                data={
                    'nested_count': nested_count,
                    'media_count': media_count,
                    'archive_count': archive_count,
                    'direct_files': direct_files,
                    'direct_dirs': direct_dirs,
                    'skipped_count': skipped_count,
                    'operation_id': operation_id
                }
            )
            
        except Exception as e:
            if on_log:
                on_log(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return DissolvefOutput(success=False, message=f"å¤„ç†å¤±è´¥: {e}")
    
    async def _dissolve_nested_with_similarity(
        self,
        path: Path,
        exclude_keywords: List[str],
        preview: bool,
        threshold: float,
        on_log: Optional[Callable[[str], None]] = None
    ) -> Tuple[int, int, List[DissolveOperation]]:
        """å¸¦ç›¸ä¼¼åº¦æ£€æµ‹çš„åµŒå¥—æ–‡ä»¶å¤¹è§£æ•£"""
        processed_count = 0
        skipped_count = 0
        operations: List[DissolveOperation] = []
        
        for root, dirs, files in os.walk(path):
            root_path = Path(root)
            
            # æ£€æŸ¥æŽ’é™¤å…³é”®è¯
            if any(keyword in str(root) for keyword in exclude_keywords):
                continue
            
            # åªæœ‰ä¸€ä¸ªå­æ–‡ä»¶å¤¹ä¸”æ²¡æœ‰æ–‡ä»¶
            if len(dirs) == 1 and not files:
                subfolder_name = dirs[0]
                subfolder_path = root_path / subfolder_name
                parent_name = root_path.name
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = calculate_similarity(parent_name, subfolder_name)
                
                if threshold > 0 and similarity < threshold:
                    skipped_count += 1
                    if on_log:
                        on_log(f"  â­ï¸ è·³è¿‡: {parent_name}/{subfolder_name} (ç›¸ä¼¼åº¦ {similarity:.0%} < {threshold:.0%})")
                    continue
                
                # æ‰¾åˆ°æœ€æ·±å±‚çš„å•ä¸€å­æ–‡ä»¶å¤¹
                current_subfolder = subfolder_path
                while True:
                    sub_items = list(current_subfolder.iterdir())
                    sub_dirs = [item for item in sub_items if item.is_dir()]
                    sub_files = [item for item in sub_items if item.is_file()]
                    
                    if len(sub_dirs) == 1 and not sub_files:
                        current_subfolder = sub_dirs[0]
                    else:
                        break
                
                if on_log:
                    on_log(f"  ðŸ“ è§£æ•£: {parent_name}/{subfolder_name} (ç›¸ä¼¼åº¦ {similarity:.0%})")
                
                if not preview:
                    try:
                        # ç§»åŠ¨å†…å®¹åˆ°çˆ¶æ–‡ä»¶å¤¹
                        for item in current_subfolder.iterdir():
                            dst_path = root_path / item.name
                            # å¤„ç†åç§°å†²çª
                            if dst_path.exists():
                                counter = 1
                                while dst_path.exists():
                                    new_name = f"{item.stem}_{counter}{item.suffix}" if item.suffix else f"{item.name}_{counter}"
                                    dst_path = root_path / new_name
                                    counter += 1
                            
                            shutil.move(str(item), str(dst_path))
                            operations.append(DissolveOperation(
                                type='move',
                                src=str(item),
                                dst=str(dst_path),
                                timestamp=datetime.now().isoformat()
                            ))
                        
                        # åˆ é™¤ç©ºæ–‡ä»¶å¤¹
                        if not any(current_subfolder.iterdir()):
                            shutil.rmtree(str(subfolder_path))
                            operations.append(DissolveOperation(
                                type='delete_dir',
                                src=str(subfolder_path),
                                timestamp=datetime.now().isoformat()
                            ))
                        
                        processed_count += 1
                    except Exception as e:
                        if on_log:
                            on_log(f"  âŒ å¤±è´¥: {e}")
                else:
                    processed_count += 1
        
        return processed_count, skipped_count, operations
    
    async def _dissolve_archive_with_similarity(
        self,
        path: Path,
        exclude_keywords: List[str],
        preview: bool,
        threshold: float,
        on_log: Optional[Callable[[str], None]] = None
    ) -> Tuple[int, int, List[DissolveOperation]]:
        """å¸¦ç›¸ä¼¼åº¦æ£€æµ‹çš„å•åŽ‹ç¼©åŒ…æ–‡ä»¶å¤¹è§£æ•£"""
        ARCHIVE_FORMATS = {'.zip', '.rar', '.7z', '.cbz', '.cbr'}
        
        processed_count = 0
        skipped_count = 0
        operations: List[DissolveOperation] = []
        
        for root, dirs, files in os.walk(path, topdown=False):
            root_path = Path(root)
            
            # æ£€æŸ¥æŽ’é™¤å…³é”®è¯
            if any(keyword in str(root) for keyword in exclude_keywords):
                continue
            
            try:
                items = list(root_path.iterdir())
                file_items = [item for item in items if item.is_file()]
                dir_items = [item for item in items if item.is_dir()]
                
                # è¿‡æ»¤åŽ‹ç¼©åŒ…æ–‡ä»¶
                archive_files = [f for f in file_items if f.suffix.lower() in ARCHIVE_FORMATS]
                
                # åªæœ‰ä¸€ä¸ªåŽ‹ç¼©åŒ…ä¸”æ²¡æœ‰å…¶ä»–æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
                if len(archive_files) == 1 and len(file_items) == 1 and len(dir_items) == 0:
                    archive_file = archive_files[0]
                    folder_name = root_path.name
                    archive_name = archive_file.stem
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    similarity = calculate_similarity(folder_name, archive_name)
                    
                    if threshold > 0 and similarity < threshold:
                        skipped_count += 1
                        if on_log:
                            on_log(f"  â­ï¸ è·³è¿‡: {folder_name}/{archive_file.name} (ç›¸ä¼¼åº¦ {similarity:.0%} < {threshold:.0%})")
                        continue
                    
                    parent_dir = root_path.parent
                    target_path = parent_dir / archive_file.name
                    
                    # å¤„ç†åç§°å†²çª
                    if target_path.exists():
                        counter = 1
                        while target_path.exists():
                            new_name = f"{archive_file.stem}_{counter}{archive_file.suffix}"
                            target_path = parent_dir / new_name
                            counter += 1
                    
                    if on_log:
                        on_log(f"  ðŸ“¦ è§£æ•£: {folder_name}/{archive_file.name} (ç›¸ä¼¼åº¦ {similarity:.0%})")
                    
                    if not preview:
                        try:
                            shutil.move(str(archive_file), str(target_path))
                            operations.append(DissolveOperation(
                                type='move',
                                src=str(archive_file),
                                dst=str(target_path),
                                timestamp=datetime.now().isoformat()
                            ))
                            
                            os.rmdir(str(root_path))
                            operations.append(DissolveOperation(
                                type='delete_dir',
                                src=str(root_path),
                                timestamp=datetime.now().isoformat()
                            ))
                            
                            processed_count += 1
                        except Exception as e:
                            if on_log:
                                on_log(f"  âŒ å¤±è´¥: {e}")
                    else:
                        processed_count += 1
                        
            except Exception as e:
                if on_log:
                    on_log(f"  âŒ å¤„ç†å¤±è´¥: {root_path} - {e}")
        
        return processed_count, skipped_count, operations
