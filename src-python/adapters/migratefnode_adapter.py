"""
migratefnode é€‚é…å™¨
æ–‡ä»¶è¿ç§»å·¥å…· - æ‰«æå¹¶è¿ç§»æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•

æ”¯æŒä¸¤é˜¶æ®µæ“ä½œï¼š
1. scan: æ‰«ææºç›®å½•ï¼Œç”Ÿæˆè¿ç§»è®¡åˆ’
2. migrate: æ ¹æ®è®¡åˆ’æ‰§è¡Œè¿ç§»
"""

import io
import os
import sys
import shutil
import json
from pathlib import Path
from typing import Callable, Dict, List, Optional
from datetime import datetime

from pydantic import Field

from .base import BaseAdapter, AdapterInput, AdapterOutput


def _ensure_utf8_output():
    """ç¡®ä¿ stdout/stderr ä½¿ç”¨ UTF-8 ç¼–ç ï¼Œé¿å… Windows GBK ç¼–ç é—®é¢˜"""
    if sys.platform == 'win32':
        os.environ.setdefault('PYTHONIOENCODING', 'utf-8')
        if hasattr(sys.stdout, 'buffer'):
            sys.stdout = io.TextIOWrapper(
                sys.stdout.buffer, 
                encoding='utf-8', 
                errors='replace',
                line_buffering=True
            )
        if hasattr(sys.stderr, 'buffer'):
            sys.stderr = io.TextIOWrapper(
                sys.stderr.buffer, 
                encoding='utf-8', 
                errors='replace',
                line_buffering=True
            )


_ensure_utf8_output()


class MigrateFNodeInput(AdapterInput):
    """migratefnode è¾“å…¥å‚æ•°"""
    action: str = Field(default="scan", description="æ“ä½œç±»å‹: scan, migrate, full")
    path: str = Field(default="", description="æºç›®å½•è·¯å¾„")
    target_path: str = Field(default="", description="ç›®æ ‡ç›®å½•è·¯å¾„")
    pattern: str = Field(default="*", description="æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œå¦‚ *.jpg, *.png")
    recursive: bool = Field(default=True, description="æ˜¯å¦é€’å½’æ‰«æå­ç›®å½•")
    overwrite: bool = Field(default=False, description="æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶")
    dry_run: bool = Field(default=True, description="æ¨¡æ‹Ÿæ‰§è¡Œï¼Œä¸å®é™…ç§»åŠ¨æ–‡ä»¶")
    preserve_structure: bool = Field(default=True, description="ä¿æŒç›®å½•ç»“æ„")
    config_path: str = Field(default="", description="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äº migrate æ“ä½œï¼‰")


class MigrateFNodeOutput(AdapterOutput):
    """migratefnode è¾“å‡ºç»“æœ"""
    config_path: str = Field(default="", description="ç”Ÿæˆçš„é…ç½®æ–‡ä»¶è·¯å¾„")
    total_files: int = Field(default=0, description="æ‰«æåˆ°çš„æ–‡ä»¶æ€»æ•°")
    total_size: int = Field(default=0, description="æ–‡ä»¶æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰")
    moved_count: int = Field(default=0, description="æˆåŠŸè¿ç§»çš„æ•°é‡")
    skipped_count: int = Field(default=0, description="è·³è¿‡çš„æ•°é‡")
    failed_count: int = Field(default=0, description="å¤±è´¥çš„æ•°é‡")
    file_list: Optional[List[Dict]] = Field(default=None, description="æ–‡ä»¶åˆ—è¡¨")


class MigrateFNodeAdapter(BaseAdapter):
    """
    migratefnode é€‚é…å™¨
    
    åŠŸèƒ½ï¼šæ‰«æå¹¶è¿ç§»æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
    æ”¯æŒä¸¤é˜¶æ®µæ“ä½œï¼šscan -> migrate
    """
    
    name = "migratefnode"
    display_name = "æ–‡ä»¶è¿ç§»"
    description = "æ‰«æå¹¶è¿ç§»æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•ï¼Œæ”¯æŒæ¨¡å¼åŒ¹é…å’Œç›®å½•ç»“æ„ä¿æŒ"
    category = "file"
    icon = "ğŸ“"
    required_packages = []  # æ— å¤–éƒ¨ä¾èµ–
    input_schema = MigrateFNodeInput
    output_schema = MigrateFNodeOutput
    
    def _import_module(self) -> Dict:
        """æ— éœ€å¤–éƒ¨æ¨¡å—ï¼Œè¿”å›ç©ºå­—å…¸"""
        return {}
    
    async def execute(
        self,
        input_data: MigrateFNodeInput,
        on_progress: Optional[Callable[[int, str], None]] = None,
        on_log: Optional[Callable[[str], None]] = None
    ) -> MigrateFNodeOutput:
        """æ‰§è¡Œ migratefnode åŠŸèƒ½"""
        action = input_data.action.lower()
        
        if action == "scan":
            return await self._scan(input_data, on_progress, on_log)
        elif action == "migrate":
            return await self._migrate(input_data, on_progress, on_log)
        else:
            # full æ¨¡å¼ï¼šå…ˆæ‰«æå†è¿ç§»
            return await self._full(input_data, on_progress, on_log)
    
    async def _scan(
        self,
        input_data: MigrateFNodeInput,
        on_progress: Optional[Callable[[int, str], None]] = None,
        on_log: Optional[Callable[[str], None]] = None
    ) -> MigrateFNodeOutput:
        """é˜¶æ®µ1ï¼šæ‰«ææºç›®å½•"""
        try:
            normalized_path = os.path.normpath(input_data.path)
            source_path = Path(normalized_path)
        except Exception as e:
            return MigrateFNodeOutput(
                success=False,
                message=f"è·¯å¾„æ ¼å¼é”™è¯¯: {str(e)}"
            )
        
        if not source_path.exists():
            return MigrateFNodeOutput(
                success=False,
                message=f"æºè·¯å¾„ä¸å­˜åœ¨: {input_data.path}"
            )
        
        if not source_path.is_dir():
            return MigrateFNodeOutput(
                success=False,
                message=f"æºè·¯å¾„ä¸æ˜¯ç›®å½•: {input_data.path}"
            )
        
        try:
            if on_log:
                on_log(f"å¼€å§‹æ‰«æç›®å½•: {input_data.path}")
            if on_progress:
                on_progress(10, "æ­£åœ¨æ‰«ææ–‡ä»¶...")
            
            # æ‰«ææ–‡ä»¶
            file_list = []
            total_size = 0
            pattern = input_data.pattern
            
            if input_data.recursive:
                files = list(source_path.rglob(pattern))
            else:
                files = list(source_path.glob(pattern))
            
            if on_progress:
                on_progress(30, f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œæ­£åœ¨åˆ†æ...")
            
            for i, file_path in enumerate(files):
                if file_path.is_file():
                    try:
                        file_size = file_path.stat().st_size
                        rel_path = file_path.relative_to(source_path)
                        
                        file_list.append({
                            'source': str(file_path),
                            'relative': str(rel_path),
                            'size': file_size,
                            'status': 'pending'
                        })
                        total_size += file_size
                    except Exception as e:
                        if on_log:
                            on_log(f"è·³è¿‡æ–‡ä»¶ {file_path}: {e}")
                
                if on_progress and i % 100 == 0:
                    progress = 30 + int((i / len(files)) * 40)
                    on_progress(progress, f"å·²æ‰«æ {i}/{len(files)} ä¸ªæ–‡ä»¶")
            
            if on_progress:
                on_progress(80, "æ­£åœ¨ç”Ÿæˆé…ç½®æ–‡ä»¶...")
            
            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            config = {
                'source_path': str(source_path),
                'target_path': input_data.target_path,
                'pattern': pattern,
                'recursive': input_data.recursive,
                'preserve_structure': input_data.preserve_structure,
                'overwrite': input_data.overwrite,
                'files': file_list,
                'created_at': datetime.now().isoformat()
            }
            
            config_filename = f"migrate_config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            config_path = source_path / config_filename
            
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            
            if on_progress:
                on_progress(100, "æ‰«æå®Œæˆ")
            
            if on_log:
                on_log(f"æ‰«æå®Œæˆï¼Œå…± {len(file_list)} ä¸ªæ–‡ä»¶")
                on_log(f"é…ç½®æ–‡ä»¶: {config_path}")
            
            return MigrateFNodeOutput(
                success=True,
                message=f"æ‰«æå®Œæˆï¼Œå…± {len(file_list)} ä¸ªæ–‡ä»¶",
                config_path=str(config_path),
                total_files=len(file_list),
                total_size=total_size,
                file_list=file_list,
                output_path=input_data.path,
                data={
                    'config_path': str(config_path),
                    'total_files': len(file_list),
                    'total_size': total_size,
                    'file_list': file_list[:100]  # é™åˆ¶è¿”å›æ•°é‡
                }
            )
            
        except Exception as e:
            import traceback
            if on_log:
                on_log(f"æ‰«æå¤±è´¥: {str(e)}")
                on_log(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return MigrateFNodeOutput(
                success=False,
                message=f"æ‰«æå¤±è´¥: {type(e).__name__}: {str(e)}"
            )
    
    async def _migrate(
        self,
        input_data: MigrateFNodeInput,
        on_progress: Optional[Callable[[int, str], None]] = None,
        on_log: Optional[Callable[[str], None]] = None
    ) -> MigrateFNodeOutput:
        """é˜¶æ®µ2ï¼šæ‰§è¡Œè¿ç§»"""
        config_path = Path(input_data.config_path)
        
        if not config_path.exists():
            return MigrateFNodeOutput(
                success=False,
                message=f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {input_data.config_path}"
            )
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            if on_log:
                on_log(f"å¼€å§‹è¿ç§»ï¼Œé…ç½®æ–‡ä»¶: {input_data.config_path}")
            if on_progress:
                on_progress(10, "æ­£åœ¨è¯»å–é…ç½®...")
            
            target_path = Path(input_data.target_path or config.get('target_path', ''))
            if not target_path:
                return MigrateFNodeOutput(
                    success=False,
                    message="æœªæŒ‡å®šç›®æ ‡è·¯å¾„"
                )
            
            source_path = Path(config['source_path'])
            files = config.get('files', [])
            preserve_structure = config.get('preserve_structure', True)
            overwrite = input_data.overwrite or config.get('overwrite', False)
            dry_run = input_data.dry_run
            
            moved_count = 0
            skipped_count = 0
            failed_count = 0
            
            if on_progress:
                on_progress(20, f"å‡†å¤‡è¿ç§» {len(files)} ä¸ªæ–‡ä»¶...")
            
            for i, file_info in enumerate(files):
                src = Path(file_info['source'])
                
                if preserve_structure:
                    rel_path = file_info.get('relative', src.name)
                    dst = target_path / rel_path
                else:
                    dst = target_path / src.name
                
                try:
                    if not src.exists():
                        file_info['status'] = 'skipped'
                        file_info['reason'] = 'æºæ–‡ä»¶ä¸å­˜åœ¨'
                        skipped_count += 1
                        continue
                    
                    if dst.exists() and not overwrite:
                        file_info['status'] = 'skipped'
                        file_info['reason'] = 'ç›®æ ‡å·²å­˜åœ¨'
                        skipped_count += 1
                        continue
                    
                    if not dry_run:
                        dst.parent.mkdir(parents=True, exist_ok=True)
                        shutil.move(str(src), str(dst))
                    
                    file_info['status'] = 'moved'
                    file_info['target'] = str(dst)
                    moved_count += 1
                    
                except Exception as e:
                    file_info['status'] = 'failed'
                    file_info['reason'] = str(e)
                    failed_count += 1
                    if on_log:
                        on_log(f"è¿ç§»å¤±è´¥ {src}: {e}")
                
                if on_progress and i % 50 == 0:
                    progress = 20 + int((i / len(files)) * 70)
                    on_progress(progress, f"å·²å¤„ç† {i}/{len(files)} ä¸ªæ–‡ä»¶")
            
            # æ›´æ–°é…ç½®æ–‡ä»¶
            config['files'] = files
            config['migrated_at'] = datetime.now().isoformat()
            config['dry_run'] = dry_run
            
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            
            if on_progress:
                on_progress(100, "è¿ç§»å®Œæˆ")
            
            mode_text = "æ¨¡æ‹Ÿ" if dry_run else "å®é™…"
            if on_log:
                on_log(f"{mode_text}è¿ç§»å®Œæˆ: {moved_count} æˆåŠŸ, {skipped_count} è·³è¿‡, {failed_count} å¤±è´¥")
            
            return MigrateFNodeOutput(
                success=True,
                message=f"{mode_text}è¿ç§»å®Œæˆ: {moved_count} æˆåŠŸ, {skipped_count} è·³è¿‡, {failed_count} å¤±è´¥",
                config_path=str(config_path),
                total_files=len(files),
                moved_count=moved_count,
                skipped_count=skipped_count,
                failed_count=failed_count,
                stats={
                    'moved': moved_count,
                    'skipped': skipped_count,
                    'failed': failed_count,
                    'total': len(files)
                },
                data={
                    'moved_count': moved_count,
                    'skipped_count': skipped_count,
                    'failed_count': failed_count,
                    'total_files': len(files),
                    'dry_run': dry_run
                }
            )
            
        except Exception as e:
            if on_log:
                on_log(f"è¿ç§»å¤±è´¥: {str(e)}")
            return MigrateFNodeOutput(
                success=False,
                message=f"è¿ç§»å¤±è´¥: {type(e).__name__}: {str(e)}"
            )
    
    async def _full(
        self,
        input_data: MigrateFNodeInput,
        on_progress: Optional[Callable[[int, str], None]] = None,
        on_log: Optional[Callable[[str], None]] = None
    ) -> MigrateFNodeOutput:
        """å®Œæ•´æµç¨‹ï¼šæ‰«æ + è¿ç§»"""
        # å…ˆæ‰«æ
        scan_result = await self._scan(input_data, on_progress, on_log)
        
        if not scan_result.success:
            return scan_result
        
        # å†è¿ç§»
        input_data.config_path = scan_result.config_path
        migrate_result = await self._migrate(input_data, on_progress, on_log)
        
        # åˆå¹¶ç»“æœ
        migrate_result.total_size = scan_result.total_size
        
        return migrate_result
